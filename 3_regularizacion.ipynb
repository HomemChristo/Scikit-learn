{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de Lasso y Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los modelos de sklearn \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las metricas de entrenamiento y el error medio cuadrado\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             rank       score        high         low         gdp      family  \\\n",
      "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
      "mean    78.000000    5.354019    5.452326    5.255713    0.984718    1.188898   \n",
      "std     44.888751    1.131230    1.118542    1.145030    0.420793    0.287263   \n",
      "min      1.000000    2.693000    2.864884    2.521116    0.000000    0.000000   \n",
      "25%     39.500000    4.505500    4.608172    4.374955    0.663371    1.042635   \n",
      "50%     78.000000    5.279000    5.370032    5.193152    1.064578    1.253918   \n",
      "75%    116.500000    6.101500    6.194600    6.006527    1.318027    1.414316   \n",
      "max    155.000000    7.537000    7.622030    7.479556    1.870766    1.610574   \n",
      "\n",
      "           lifexp     freedom  generosity  corruption    dystopia  \n",
      "count  155.000000  155.000000  155.000000  155.000000  155.000000  \n",
      "mean     0.551341    0.408786    0.246883    0.123120    1.850238  \n",
      "std      0.237073    0.149997    0.134780    0.101661    0.500028  \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.377914  \n",
      "25%      0.369866    0.303677    0.154106    0.057271    1.591291  \n",
      "50%      0.606042    0.437454    0.231538    0.089848    1.832910  \n",
      "75%      0.723008    0.516561    0.323762    0.153296    2.144654  \n",
      "max      0.949492    0.658249    0.838075    0.464308    3.117485  \n"
     ]
    }
   ],
   "source": [
    "# Importamos el dataset del 2017 \n",
    "dataset = pd.read_csv('./data/felicidad.csv')\n",
    "# Mostramos el reporte estadistico\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a elegir los features que vamos a usar\n",
    "X = dataset[['gdp', 'family', 'lifexp', 'freedom' , 'corruption' , 'generosity', 'dystopia']]\n",
    "# Definimos nuestro objetivo, que sera nuestro data set, pero solo en la columna score \n",
    "y = dataset[['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 7)\n",
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos los conjutos que creamos \n",
    "# En nuestros features tendremos definidos 155 registros, uno por cada pais, 7 colunas 1 por cada pais \n",
    "print(X.shape)\n",
    "# Y 155 para nuestra columna para nuestro target \n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí vamos a partir nuestro entrenaminto en training y test, no hay olvidar el orden\n",
    "# Con el test size elejimos nuestro porcetaje de datos para training \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí definimos nuestros regresores uno por 1 y llamamos el fit o ajuste \n",
    "modelLinear = LinearRegression().fit(X_train, y_train)\n",
    "# Vamos calcular la prediccion que nos bota con la funcion predict con la regresion lineal y le vamos a mandar el test \n",
    "y_predict_linear = modelLinear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos alpha, que es valor labda y entre mas valor tenga alpha en lasso mas penalizacion vamos a tener y lo entrenamos con la función fit \n",
    "modelLasso = Lasso(alpha=0.2).fit(X_train, y_train)\n",
    "# Hacemos una prediccion para ver si es mejor o peor de lo que teniamos en el modelo lineal sobre exactamente los mismos datos que teníamos anteriormente \n",
    "y_predict_lasso = modelLasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la misma predicción, pero para nuestra regresion ridge \n",
    "modelRidge = Ridge(alpha=1).fit(X_train, y_train)\n",
    "# Calculamos el valor predicho para nuestra regresión ridge \n",
    "y_predict_ridge = modelRidge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos otra prediccion más, utilizando el modelo ElasticNet \n",
    "modelElasticNet = ElasticNet(random_state=0,alpha=0.01).fit(X_train, y_train)\n",
    "# Calculamos el valor predicho para nuestra regresión ridge \n",
    "y_pred_elastic = modelElasticNet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear loss:  8.683338549316208e-08\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la perdida para cada uno de los modelos que entrenamos, empezaremos con nuestro modelo lineal, con el error medio cuadratico y lo vamos a aplicar con los datos de prueba con la prediccion que hicimos \n",
    "linear_loss = mean_squared_error(y_test, y_predict_linear)\n",
    "# Mostramos la perdida lineal con la variable que acabamos de calcular\n",
    "print(\"Linear loss: \", linear_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Loss.  0.7879892236198014\n"
     ]
    }
   ],
   "source": [
    "# Mostramos nuestra perdida Lasso, con la variable lasso loss \n",
    "lasso_loss = mean_squared_error(y_test, y_predict_lasso)\n",
    "print(\"Lasso Loss. \", lasso_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge loss:  0.005661076879049968\n"
     ]
    }
   ],
   "source": [
    "# Mostramos nuestra perdida de Ridge con la variable lasso loss \n",
    "ridge_loss = mean_squared_error(y_test, y_predict_ridge)\n",
    "print(\"Ridge loss: \", ridge_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Loss:  0.00878723801597527\n"
     ]
    }
   ],
   "source": [
    "# Mostramos nuestra perdida de ElasticNet\n",
    "elastic_loss = mean_squared_error(y_test, y_pred_elastic)\n",
    "print('ElasticNet Loss: ', elastic_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Coeficientes lasso: \n",
      "[0.90652194 0.         0.         0.         0.         0.\n",
      " 0.20631307]\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos las coficientes para ver como afecta a cada una de las regresiones \n",
    "# La lines \"=\"*32 lo unico que hara es repetirme si simbolo de igual 32 veces \n",
    "print(\"=\"*32)\n",
    "print(\"Coeficientes lasso: \")\n",
    "# Esta informacion la podemos encontrar en la variable coef_ \n",
    "print(modelLasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Coeficientes ridge:\n",
      "[[1.07424048 0.9542686  0.85881004 0.85250818 0.67393391 0.781227\n",
      "  0.96125657]]\n"
     ]
    }
   ],
   "source": [
    "# Hacemos lo mismo con ridge \n",
    "print(\"=\"*32)\n",
    "print(\"Coeficientes ridge:\")\n",
    "print(modelRidge.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Coeficientes ElasticNet:\n",
      "[1.10922172 0.94382162 0.80787459 0.83275311 0.5323034  0.72566323\n",
      " 0.95337165]\n"
     ]
    }
   ],
   "source": [
    "# Hacemos lo mismo con ridge \n",
    "print(\"=\"*32)\n",
    "print(\"Coeficientes ElasticNet:\")\n",
    "print(modelElasticNet.coef_) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
